{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZzq7b_UmAP8",
        "outputId": "ae6ca3f9-fcba-433c-b51e-04554b078f67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'DataScience_MPhill_practicals' already exists and is not an empty directory.\n",
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.4)\n"
          ]
        }
      ],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone https://github.com/loressa/DataScience_MPhill_practicals.git\n",
        "# Install the pydicom package\n",
        "!pip install pydicom\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zELAj5eEn9EV"
      },
      "outputs": [],
      "source": [
        "import pydicom\n",
        "from pydicom import dcmread\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import torchmetrics\n",
        "from torchmetrics.classification import BinaryAccuracy\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cz2wPue2sQR9"
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = self.conv_block(in_channels, 16, 3, 1, 1)\n",
        "    self.maxpool1 = self.maxpool_block(2, 2, 0)\n",
        "    self.conv2 = self.conv_block(16, 32, 3, 1, 1)\n",
        "    self.maxpool2 = self.maxpool_block(2, 2, 0)\n",
        "    self.conv3 = self.conv_block(32, 64, 3, 1, 1)\n",
        "    self.maxpool3 = self.maxpool_block(2, 2, 0)\n",
        "    self.middle = self.conv_block(64, 128, 3, 1, 1)\n",
        "    self.upsample3 = self.transposed_block(128, 64, 3, 2, 1, 1)\n",
        "    self.upconv3 = self.conv_block(128, 64, 3, 1, 1)\n",
        "    self.upsample2 = self.transposed_block(64, 32, 3, 2, 1, 1)\n",
        "    self.upconv2 = self.conv_block(64, 32, 3, 1, 1)\n",
        "    self.upsample1 = self.transposed_block(32, 16, 3, 2, 1, 1)\n",
        "    self.upconv1 = self.conv_block(32, 16, 3, 1, 1)\n",
        "    self.final = self.final_layer(16, 1, 1, 1, 0)\n",
        "\n",
        "  def conv_block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "    convolution = nn.Sequential(\n",
        "                  nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "                  nn.BatchNorm2d(out_channels),\n",
        "                  nn.ReLU(inplace=True),\n",
        "                  nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "                  nn.BatchNorm2d(out_channels),\n",
        "                  nn.ReLU(inplace=True))\n",
        "    return convolution\n",
        "\n",
        "  def maxpool_block(self, kernel_size, stride, padding):\n",
        "      maxpool = nn.Sequential(nn.MaxPool2d(kernel_size=kernel_size, stride=stride, padding=padding),\n",
        "      nn.Dropout2d(0.5))\n",
        "      return maxpool\n",
        "\n",
        "  def transposed_block(self, in_channels, out_channels, kernel_size, stride, padding, output_padding):\n",
        "      transposed = torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride,\n",
        "      padding=padding, output_padding=output_padding)\n",
        "      return transposed\n",
        "\n",
        "  def final_layer(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "      final = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "      return final\n",
        "\n",
        "  def forward(self, x):\n",
        "      # downsampling part\n",
        "      conv1 = self.conv1(x)\n",
        "      maxpool1 = self.maxpool1(conv1)\n",
        "      conv2 = self.conv2(maxpool1)\n",
        "      maxpool2 = self.maxpool2(conv2)\n",
        "      conv3 = self.conv3(maxpool2)\n",
        "      maxpool3 = self.maxpool3(conv3)\n",
        "      # middle part\n",
        "      middle = self.middle(maxpool3)\n",
        "      # upsampling part\n",
        "      upsample3 = self.upsample3(middle)\n",
        "      upconv3 = self.upconv3(torch.cat([upsample3, conv3], 1))\n",
        "      upsample2 = self.upsample2(upconv3)\n",
        "      upconv2 = self.upconv2(torch.cat([upsample2, conv2], 1))\n",
        "      upsample1 = self.upsample1(upconv2)\n",
        "      upconv1 = self.upconv1(torch.cat([upsample1, conv1], 1))\n",
        "      final_layer = self.final(upconv1)\n",
        "      return final_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VsEk1xSMXOpV"
      },
      "outputs": [],
      "source": [
        "# Function to convert DICOM files to numpy array\n",
        "def dicom_to_numpy(dicom_dir):\n",
        "    dicom_slices = [dcmread(os.path.join(dicom_dir, filename)) for filename in os.listdir(dicom_dir)]\n",
        "    dicom_slices.sort(key=lambda x: float(x.ImagePositionPatient[2]))  # Sort slices by z-coordinate\n",
        "    pixel_arrays = [slice.pixel_array for slice in dicom_slices]\n",
        "    volume = np.stack(pixel_arrays, axis=-1)\n",
        "    return volume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "65PmuyoZXQii"
      },
      "outputs": [],
      "source": [
        "def prepare_images_tensor(dataset_dir):\n",
        "  # List of case directories\n",
        "  case_dirs = [os.path.join(dataset_dir, f\"Case_{str(i).zfill(3)}\") for i in range(0, 12)]\n",
        "  # Convert DICOM datasets to numpy arrays\n",
        "  case_volumes = []\n",
        "  for case_dir in case_dirs:\n",
        "      case_volume = dicom_to_numpy(case_dir)\n",
        "      case_volumes.append(case_volume)\n",
        "  # Reshape each case volume to (512, 512) format\n",
        "  reshaped_slices = []\n",
        "\n",
        "  for case_volume in case_volumes:\n",
        "      num_slices = case_volume.shape[-1]  # Get the number of slices\n",
        "      for i in range(num_slices):\n",
        "          reshaped_slices.append(case_volume[:, :, i])\n",
        "\n",
        "  # Combine all reshaped slices into a single array\n",
        "  combined_slices = np.stack(reshaped_slices, axis=0)\n",
        "  # Convert combined_slices to a PyTorch tensor with data type torch.float32\n",
        "  images_tensor = torch.from_numpy(combined_slices.astype(np.float32))\n",
        "  return images_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "1gpkaFo3XwXt"
      },
      "outputs": [],
      "source": [
        "def prepare_masks_tensor(dataset_dir):\n",
        "  # List to store all the loaded 3D arrays\n",
        "  masks_all = []\n",
        "  # Iterate over each file\n",
        "  for i in range(12):\n",
        "      # Construct the file path for each case\n",
        "      image_file = os.path.join(dataset_dir, f\"Case_{str(i).zfill(3)}_seg.npz\")\n",
        "\n",
        "      # Load segmentation masks from the NPZ file\n",
        "      segmentation_data = np.load(image_file)\n",
        "      image_array = segmentation_data['masks']\n",
        "      # print(image_array.shape)\n",
        "      for j in range(len(image_array)):\n",
        "        image_array_j = image_array[j,:,:]\n",
        "        # Append the 3D array to the list\n",
        "        masks_all.append(image_array_j)\n",
        "    # Combine all reshaped slices into a single array\n",
        "  masks_all = np.stack(masks_all, axis=0)\n",
        "  # Convert combined_slices to a PyTorch tensor with data type torch.float32\n",
        "  masks_tensor = torch.from_numpy(masks_all.astype(np.float32))\n",
        "  return masks_tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ieebH_kPYZXt"
      },
      "outputs": [],
      "source": [
        "def split_dataset(images_tensor, masks_tensor):\n",
        "  train_samples = 1151\n",
        "  # Split the tensors into train and test sets\n",
        "  train_images = images_tensor[:train_samples]\n",
        "  train_masks = masks_tensor[:train_samples]\n",
        "  test_images = images_tensor[train_samples:]\n",
        "  test_masks = masks_tensor[train_samples:]\n",
        "  # Add a new channel dimension\n",
        "  train_images = train_images.unsqueeze(1)\n",
        "  train_masks = train_masks.unsqueeze(1)\n",
        "  test_images = test_images.unsqueeze(1)\n",
        "  test_masks = test_masks.unsqueeze(1)\n",
        "  return train_images, train_masks, test_images, test_masks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "rVcT0jv8Kfj0"
      },
      "outputs": [],
      "source": [
        "def soft_dice_loss(pred, target, smooth=1e-5):\n",
        "    intersection = torch.sum(pred * target)\n",
        "    dice_coeff = (2. * intersection + smooth) / (torch.sum(pred) + torch.sum(target) + smooth)\n",
        "    dice_loss = 1. - dice_coeff\n",
        "    return dice_loss\n",
        "\n",
        "def custom_loss(pred, target, alpha=0.5):\n",
        "    bce_loss = torch.nn.BCEWithLogitsLoss()(pred, target)\n",
        "    dice_loss = soft_dice_loss(torch.sigmoid(pred), target)\n",
        "    total_loss = alpha * bce_loss + (1 - alpha) * dice_loss\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "l63u_nVoc_1j"
      },
      "outputs": [],
      "source": [
        "def training(model, train_images, train_masks, device, epochs=10, learning_rate=0.1):\n",
        "    model.to(device)\n",
        "    train_loader = DataLoader(TensorDataset(train_images, train_masks), batch_size=3, shuffle=True)\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "    accuracy_function = BinaryAccuracy(threshold=0.5).to(device)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Set the model in training mode\n",
        "        model.train()\n",
        "        # Initialize the total training loss and training accuracy\n",
        "        epoch_train_loss = 0.0\n",
        "        epoch_train_accuracy = 0.0\n",
        "\n",
        "        # Loop over the training set\n",
        "        for (x, y) in tqdm(train_loader, desc=f'Epoch {epoch+1}'):\n",
        "            # Send the input to the device\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            # Perform a forward pass and calculate the training loss\n",
        "            pred = model(x)\n",
        "            loss = custom_loss(pred, y, alpha=0.5)\n",
        "            # Zero out any previously accumulated gradients, perform backpropagation, and update model parameters\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Add the loss to the total training loss so far\n",
        "            epoch_train_loss += loss.item()\n",
        "            epoch_train_accuracy += accuracy_function(torch.sigmoid(pred), y.int())\n",
        "\n",
        "        # Calculate average loss and accuracy for the epoch\n",
        "        avg_train_loss = epoch_train_loss / len(train_loader)\n",
        "        avg_train_accuracy = epoch_train_accuracy / len(train_loader)\n",
        "\n",
        "        # Append to lists\n",
        "        train_losses.append(avg_train_loss)\n",
        "        train_accuracies.append(avg_train_accuracy.item())\n",
        "\n",
        "        # Print epoch metrics\n",
        "        print(f'Epoch {epoch+1}, loss: {avg_train_loss:.4f}, Binary Accuracy: {avg_train_accuracy:.4f}')\n",
        "\n",
        "    # Save trained model\n",
        "    torch.save(model.state_dict(), 'trained_model.pt')\n",
        "\n",
        "    return model, train_losses, train_accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "h9byaM-2h8-X"
      },
      "outputs": [],
      "source": [
        "def plot_loss_accuracy(train_losses, train_accuracies):\n",
        "    epochs_idx = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Plot training loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_idx, train_losses, marker='o', color='b', linestyle='-', label='Training Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xticks(epochs_idx)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot training accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_idx, train_accuracies, marker='o', color='r', linestyle='-', label='Training Accuracy')\n",
        "    plt.title('Training Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xticks(epochs_idx)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('Training_loss_acc.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jGSIMXo0iXkq"
      },
      "outputs": [],
      "source": [
        "def dice_similarity_coefficient(pred, target, smooth=1e-5):\n",
        "  # pred = torch.sigmoid(pred)\n",
        "  pred = (pred > 0.5).float()\n",
        "  intersection = torch.sum(pred * target)\n",
        "  dice_coeff = (2. * intersection + smooth) / (torch.sum(pred) + torch.sum(target) + smooth)\n",
        "  return dice_coeff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "W8QHRXZ7lSvY"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_images, test_masks, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    test_loader = DataLoader(TensorDataset(test_images, test_masks), batch_size=1, shuffle=False)  # Batch size 1 for inference\n",
        "    accuracy_function = BinaryAccuracy(threshold=0.5).to(device)\n",
        "    real_list, pred_list, ground_list = [], [], []\n",
        "    dsc_list, accuracy_list = [], []\n",
        "    num_samples = 0\n",
        "\n",
        "    for images, masks in tqdm(test_loader, desc='Evaluating'):\n",
        "        with torch.no_grad():\n",
        "            # Move data to device\n",
        "            images, masks = images.to(device), masks.to(device)\n",
        "\n",
        "            # Make predictions\n",
        "            preds = model(images)\n",
        "            preds = torch.sigmoid(preds)\n",
        "\n",
        "            # Compute DSC for each sample\n",
        "            dsc = dice_similarity_coefficient(preds, masks, smooth=1e-5).cpu()\n",
        "            accuracy = accuracy_function(preds, masks.int())\n",
        "            dsc_list.append(dsc)\n",
        "            accuracy_list.append(accuracy.item())\n",
        "\n",
        "            # remove the batch dimension\n",
        "            real_list.append(images.squeeze(0))\n",
        "            pred_list.append(preds.squeeze(0))\n",
        "            ground_list.append(masks.squeeze(0))\n",
        "\n",
        "    return dsc_list, accuracy_list, real_list, pred_list, ground_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ToHjF5qsTO3"
      },
      "outputs": [],
      "source": [
        "def plot_dsc_accuracy_histogram(dsc_list, accuracy_list):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    # Plot histogram for Dice Similarity Coefficient\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.hist(dsc_list, bins=20, color='skyblue', edgecolor='black', alpha=0.7)\n",
        "    plt.title('Dice Similarity Coefficient Histogram')\n",
        "    plt.xlabel('Dice Similarity Coefficient')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Plot histogram for Test Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.hist(accuracy_list, bins=20, color='salmon', edgecolor='black', alpha=0.7)\n",
        "    plt.title('Accuracy Histogram')\n",
        "    plt.xlabel('Accuracy')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('dsc_accuracy_histogram.png')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "6V7DMBuOstNt"
      },
      "outputs": [],
      "source": [
        "def find_examples(images, masks, predictions, dsc_values, num_examples=3):\n",
        "    dsc_values = np.array(dsc_values)  # Convert to NumPy array\n",
        "    best_indices = np.argsort(dsc_values)[-num_examples:][::-1]\n",
        "    worst_indices = np.argsort(dsc_values)[:num_examples]\n",
        "    median_indices = np.argsort(np.abs(dsc_values - 0.5))[:num_examples]\n",
        "\n",
        "    examples = {\n",
        "        'best': [],\n",
        "        'worst': [],\n",
        "        'median': []\n",
        "    }\n",
        "\n",
        "    for index in best_indices:\n",
        "        examples['best'].append((images[index], masks[index], predictions[index]))\n",
        "    for index in worst_indices:\n",
        "        examples['worst'].append((images[index], masks[index], predictions[index]))\n",
        "    for index in median_indices:\n",
        "        examples['median'].append((images[index], masks[index], predictions[index]))\n",
        "\n",
        "    return examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "W7T6CKsxt62k"
      },
      "outputs": [],
      "source": [
        "def plot_examples(examples, save_path='example_plots/'):\n",
        "    import os\n",
        "\n",
        "    categories = ['best', 'worst', 'median']\n",
        "\n",
        "    # Create a directory to save the plots if it doesn't exist\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "    for category in categories:\n",
        "        fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(15, 15))\n",
        "        fig.suptitle(category.capitalize(), fontsize=16)  # Add category name to the main title\n",
        "\n",
        "        for i, (image, mask, prediction) in enumerate(examples[category]):\n",
        "            # Move tensors to CPU before converting to NumPy arrays\n",
        "            image_np = image.squeeze().cpu().numpy()  # Squeeze singleton dimension\n",
        "            mask_np = mask.squeeze().cpu().numpy()  # Squeeze singleton dimension\n",
        "            prediction_np = prediction.squeeze().cpu().numpy()  # Squeeze singleton dimension\n",
        "\n",
        "            axes[i, 0].imshow(image_np, cmap='gray')\n",
        "            axes[i, 0].set_title('Image')\n",
        "            axes[i, 0].axis('off')\n",
        "\n",
        "            axes[i, 1].imshow(mask_np, cmap='gray')\n",
        "            axes[i, 1].set_title('Ground Truth')\n",
        "            axes[i, 1].axis('off')\n",
        "\n",
        "            axes[i, 2].imshow(prediction_np, cmap='gray')\n",
        "            axes[i, 2].set_title('Prediction')\n",
        "            axes[i, 2].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(os.path.join(save_path, f'{category}_examples.png'))  # Save the plot\n",
        "        plt.close(fig)  # Close the figure to release memory\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl0GO90c5Fb9"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "  # Prepare traing dataset and testing dataset\n",
        "  images_dataset_dir = \"DataScience_MPhill_practicals/Dataset/Images\"\n",
        "  images_tensor = prepare_images_tensor(images_dataset_dir)\n",
        "  masks_dataset_dir = \"DataScience_MPhill_practicals/Dataset/Segmentations\"\n",
        "  masks_tensor = prepare_masks_tensor(masks_dataset_dir)\n",
        "  train_images, train_masks, test_images, test_masks = split_dataset(images_tensor, masks_tensor)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model = UNet(in_channels=1, out_channels=1).to(device)\n",
        "  model, train_losses, train_accuracies = training(model, train_images, train_masks, device, epochs=10, learning_rate=0.1)\n",
        "  plot_loss_accuracy(train_losses, train_accuracies)\n",
        "  # If predicting or evaluating from a saved model:\n",
        "  model.load_state_dict(torch.load(\"trained_model.pt\"))\n",
        "  print('Reading completed.\\nPredicting testing images using pre-trained model trained_model.pt')\n",
        "  dsc_test, accuracy_test, real_test, pred_test, ground_test = evaluate_model(model, test_images, test_masks, device)\n",
        "  plot_dsc_accuracy_histogram(dsc_test, accuracy_test)\n",
        "  examples = find_examples(real_test, ground_test, pred_test, dsc_test, num_examples=3)\n",
        "  plot_examples(examples, save_path='example_plots_test/')\n",
        "  dsc_train, accuracy_train, real_train, pred_train, ground_train = evaluate_model(model, train_images, train_masks, device)\n",
        "  plot_dsc_accuracy_histogram(dsc_train, accuracy_train)\n",
        "  examples = find_examples(real_train, ground_train, pred_train, dsc_train, num_examples=3)\n",
        "  plot_examples(examples, save_path='example_plots_train/')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
